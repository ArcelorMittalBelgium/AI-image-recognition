{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify where to find our data\n",
    "DATA_DIR = Path(\"./trafficsign_data/train\")\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    print(\"Data path incorrect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Imageset = collections.namedtuple(\"Imageset\", [\"paths\", \"labels1\", \"labels2\"])\n",
    "\n",
    "# Creates a tuple containing the image paths with corresponding labels\n",
    "def find_images():\n",
    "    paths = []\n",
    "    labels1 = []\n",
    "    labels2 = []\n",
    "\n",
    "    for directory in DATA_DIR.glob(\"./*/*/\"): # List directories 2 levels down\n",
    "        for file in directory.glob(\"*.png\"):\n",
    "            paths.append(str(file))\n",
    "            labels1.append(directory.parent.stem)\n",
    "            labels2.append(directory.stem)\n",
    "\n",
    "    return Imageset(np.array(paths), np.array(labels1), np.array(labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = find_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of content of paths, labels1, labels2\n",
    "print(np.vstack([imgs.paths, imgs.labels1, imgs.labels2]).T[0:1000:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualise a few examples\n",
    "\n",
    "# For this tutorial, lets work with a subset\n",
    "labels2_in_scope = [\"F19\", \"F49\", \"F50\", \"F87\"]\n",
    "\n",
    "for label2 in labels2_in_scope:\n",
    "    image_paths = imgs.paths[imgs.labels2 == label2]\n",
    "    \n",
    "    print('Examples for ' + label2)\n",
    "    plt.figure()\n",
    "    for i in range(4):\n",
    "        plt.subplot(141 + i) # 1 row, 4 columns, <nr of image that will be provided next>\n",
    "        image = cv2.imread(image_paths[i])\n",
    "        plt.imshow(image[:,:,::-1]) # Convert OpenCV BGR channels to RGB\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_imgs(images, channels='BGR'):\n",
    "    num_images = len(images)\n",
    "    plt.figure()\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(101 + 10 * num_images + i)\n",
    "        image = images[i]\n",
    "        if channels == 'BGR':\n",
    "            plt.imshow(image[:,:,::-1]) # Convert OpenCV BGR channels to RGB\n",
    "        elif channels == 'gray':\n",
    "            plt.imshow(image, cmap='gray')\n",
    "        else:\n",
    "            raise ValueError(\"Invalid channels value: \" + channels)\n",
    "\n",
    "easy_examples = [\n",
    "    \"./trafficsign_data/train/squares/F19/02202_12813.png\",\n",
    "    \"./trafficsign_data/train/squares/F49/00187_05053.png\",\n",
    "    \"./trafficsign_data/train/squares/F50/02206_13023.png\",\n",
    "    \"./trafficsign_data/train/squares/F87/02441_13274.png\"\n",
    "]\n",
    "hard_examples = [\n",
    "    \"./trafficsign_data/train/squares/F19/01713_06560.png\",\n",
    "    \"./trafficsign_data/train/squares/F49/02102_09354.png\",\n",
    "    \"./trafficsign_data/train/squares/F50/00900_12409.png\",\n",
    "    \"./trafficsign_data/train/squares/F87/02060_03989.png\"\n",
    "]\n",
    "\n",
    "print_imgs([cv2.imread(img) for img in easy_examples])\n",
    "print_imgs([cv2.imread(img) for img in hard_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resizing\n",
    "print_imgs([cv2.resize(cv2.imread(p), (36, 36)) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    (h, w, _) = img.shape\n",
    "    transformed_img = img[0:int(h*3/4), :]\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occlusion\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    (h, w, _) = img.shape\n",
    "    img[:, 0:int(w/4), :] = 0\n",
    "    return cv2.resize(img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirroring\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    transformed_img = cv2.flip(img, 1) # 1 = Horizontal flip\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "def transform(path, angle):\n",
    "    img = cv2.imread(path)\n",
    "    (h, w, _) = img.shape\n",
    "    matrix = cv2.getRotationMatrix2D((h/2, w/2), angle, 1)\n",
    "    transformed_img = cv2.warpAffine(img, matrix, (w, h))\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p, 10) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine transform\n",
    "def transform(path, angle):\n",
    "    img = cv2.imread(path)\n",
    "    (h, w, _) = img.shape\n",
    "    matrix = cv2.getAffineTransform(\n",
    "        np.float32([[0, 0], [0, w], [h, w]]),\n",
    "        np.float32([[0, 0], [0, w], [h, w*2/3]])\n",
    "    )\n",
    "    transformed_img = cv2.warpAffine(img, matrix, (w, h))\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p, 5) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSV colorspace\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    transformed_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    value = np.int16(transformed_img[:,:,2])\n",
    "    value += 50\n",
    "    transformed_img[:,:,2] = np.uint8(np.clip(value, 0, 255))\n",
    "    transformed_img = cv2.cvtColor(transformed_img, cv2.COLOR_HSV2BGR)\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    transformed_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples], 'gray')\n",
    "\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    transformed_img = cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blurring\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    transformed_img = cv2.blur(img,(4, 4))\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])\n",
    "\n",
    "# Order of operations matters!\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    return cv2.blur(cv2.resize(img, (36, 36)),(4, 4))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erosion\n",
    "print(\"Erosion\")\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    transformed_img = cv2.erode(img,kernel,iterations = 1)\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])\n",
    "\n",
    "print(\"Dilation\")\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    transformed_img = cv2.dilate(img,kernel,iterations = 1)\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])\n",
    "\n",
    "print(\"Erosion + dilation\")\n",
    "def transform(path):\n",
    "    img = cv2.imread(path)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    transformed_img = cv2.dilate(cv2.erode(img,kernel,iterations = 1),kernel,iterations = 1)\n",
    "    return cv2.resize(transformed_img, (36, 36))\n",
    "\n",
    "print_imgs([transform(p) for p in easy_examples])\n",
    "\n",
    "print('Original')\n",
    "print_imgs([cv2.resize(cv2.imread(p), (36, 36))  for p in easy_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
