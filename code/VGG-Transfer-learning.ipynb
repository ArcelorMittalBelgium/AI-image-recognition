{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of applying transfer learning using Tensorflow on the traffic sign dataset.\n",
    "The focus of this example was to provide an explanation on how to do transfer learning, the model trained is far from optimal for the given problem.\n",
    "\n",
    "This notebook should be run using **GPU support** unless you don't mind waiting a very long time!\n",
    "\n",
    "Download & unpack [pretrained VGG](http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz) under `../pretrained/vgg/vgg_16.ckpt`.\n",
    "\n",
    "- based on the code of omondrot https://gist.github.com/omoindrot/dedc857cdc0e680dfb1be99762990c9c\n",
    "- added model saving\n",
    "- added tensorboard visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.nets import vgg\n",
    "import tensorflow.contrib.slim.nets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training parameters\n",
    "model_path='../pretrained/vgg/vgg_16.ckpt'\n",
    "batch_size=8    # lower in case of memory problems\n",
    "num_workers=4   # set equally to the amount of cpu processors\n",
    "num_epochs1=15\n",
    "num_epochs2=15\n",
    "learning_rate1=1e-3\n",
    "learning_rate2=1e-5\n",
    "dropout_keep_prob=0.5\n",
    "weight_decay=5e-4\n",
    "\n",
    "save_path='../pretrained/vgg-finetuned'\n",
    "log_path='../logs/vgg'\n",
    "data_path='../data/trafficsigns/train'\n",
    "\n",
    "assert(os.path.isdir(save_path))\n",
    "assert(os.path.isfile(model_path))\n",
    "assert(os.path.isdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG_MEAN = [123.68, 116.78, 103.94] # average pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting input data & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to get the data paths and the annotated labels.\n",
    "'''\n",
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory)\n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\n",
    "    labels = []\n",
    "    images = []\n",
    "    label_tag = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for d in directories:\n",
    "\n",
    "        sub_directories = [k for k in os.listdir(os.path.join(data_directory, d))]\n",
    "\n",
    "        for s in sub_directories:\n",
    "            label_directory = os.path.join(data_directory,d,s)\n",
    "            file_names = [os.path.join(label_directory, f)\n",
    "                          for f in os.listdir(label_directory)\n",
    "                          if f.endswith('.png')]\n",
    "\n",
    "            for f in file_names:\n",
    "                images.append(f)\n",
    "                labels.append(label_tag)\n",
    "                num_samples += 1\n",
    "        label_tag += 1\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/trafficsigns/train/stop/B5/00983_02446.png\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly split the data into a training and validation set (for cross validation purposes)\n",
    "train_filenames, val_filenames, train_labels, val_labels = train_test_split(X, y, test_size=0.10, random_state=0)\n",
    "num_classes = len(set(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3731\n",
      "Validation set size: 415\n",
      "Number of classes: 12\n"
     ]
    }
   ],
   "source": [
    "print('Training set size: ' + str(len(train_filenames)))\n",
    "print('Validation set size: ' + str(len(val_filenames)))\n",
    "print('Number of classes: ' + str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Given a filename and label, returns a tuple (tensor, label).\n",
    "The tensor contains the pixel values of the provided image, proportionally scaled so the smallest side is 256 pixels.\n",
    "'''\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)   # read the image input file\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3) # decode jpeg to receive pixel values\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "    smallest_side = 256.0\n",
    "    height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    height = tf.to_float(height)\n",
    "    width = tf.to_float(width)\n",
    "\n",
    "    # rescale the images, keeping proportions, so the smallest side has size 'smallest_side'\n",
    "    scale = tf.cond(tf.greater(height, width), lambda: smallest_side / width,lambda: smallest_side / height)\n",
    "    new_height = tf.to_int32(height * scale)\n",
    "    new_width = tf.to_int32(width * scale)\n",
    "\n",
    "    resized_image = tf.image.resize_images(image, [new_height, new_width])\n",
    "    return resized_image, label\n",
    "\n",
    "\n",
    "# VGG preprocessing steps for training (cropping, random flipping, subtracting the mean pixel values)\n",
    "def training_preprocess(image, label):\n",
    "    # VGG expects images of size [224, 224, 3]\n",
    "    crop_image = tf.random_crop(image, [224, 224, 3]) # Randomly extract the given dimensions from the image\n",
    "    flip_image = tf.image.random_flip_left_right(crop_image) # Randomly mirror (or not)\n",
    "\n",
    "    means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "    centered_image = flip_image - means # Detract average value per channel\n",
    "\n",
    "    return centered_image, label\n",
    "\n",
    "# VGG preprocessing steps for validation (cropping, subtracting the mean pixel values)\n",
    "def val_preprocess(image, label):\n",
    "    crop_image = tf.image.resize_image_with_crop_or_pad(image, 224, 224)\n",
    "\n",
    "    means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "    centered_image = crop_image - means\n",
    "\n",
    "    return centered_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training dataset preprocessing and Tensorflow tensors adaptation\n",
    "train_filenames_tensor = tf.constant(train_filenames)\n",
    "train_labels_tensor = tf.constant(train_labels)\n",
    "train_dataset = tf.contrib.data.Dataset.from_tensor_slices((train_filenames_tensor, train_labels_tensor))\n",
    "train_dataset = train_dataset.map(_parse_function, num_threads=num_workers, output_buffer_size=batch_size)\n",
    "train_dataset = train_dataset.map(training_preprocess, num_threads=num_workers, output_buffer_size=batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "batched_train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation dataset preprocessing and Tensorflow tensors adaptation\n",
    "val_filenames_tensor = tf.constant(val_filenames)\n",
    "val_labels_tensor = tf.constant(val_labels)\n",
    "val_dataset = tf.contrib.data.Dataset.from_tensor_slices((val_filenames_tensor, val_labels_tensor))\n",
    "val_dataset = val_dataset.map(_parse_function, num_threads=num_workers, output_buffer_size=batch_size)\n",
    "val_dataset = val_dataset.map(val_preprocess,num_threads=num_workers, output_buffer_size=batch_size)\n",
    "batched_val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define an iterator that we'll use to automatically provide input during training/validation\n",
    "iterator = tf.contrib.data.Iterator.from_structure(batched_train_dataset.output_types, batched_train_dataset.output_shapes)\n",
    "images, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calling these operations will allow the generator to provide values each run\n",
    "train_init_op = iterator.make_initializer(batched_train_dataset)\n",
    "val_init_op = iterator.make_initializer(batched_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder for VGG flag\n",
    "is_training = tf.placeholder(tf.bool)   # define training or testing mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the vgg-16 model via the slim framework\n",
    "with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=weight_decay)): # Unsure what this does...\n",
    "    logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=is_training, dropout_keep_prob=dropout_keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the pretrained model weights off vgg\n",
    "with tf.name_scope('Model'):\n",
    "    # Gather the variables currently defined (meaning those of the VGG model), except for those from the last layer.\n",
    "    variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "    # Create a function that will restore the variables from the checkpoint when called\n",
    "    init_vgg = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('FC8_new'):\n",
    "    # randomly initialize the weights of the final layer of the vgg-model\n",
    "    fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "    fc8_init = tf.variables_initializer(fc8_variables) # Retrieve the initializer for the last layer\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    # define the loss function\n",
    "    tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    loss = tf.losses.get_total_loss()\n",
    "\n",
    "with tf.name_scope('SGD_fc8'):\n",
    "    # set the learning rate and the optimization model for the final layer\n",
    "    fc8_optimizer = tf.train.GradientDescentOptimizer(learning_rate1)\n",
    "    fc8_train_op = fc8_optimizer.minimize(loss, var_list=fc8_variables)\n",
    "\n",
    "with tf.name_scope('SGD_all'):\n",
    "    # set the learning rate for the general model (very small value as we are not retraining the mode from scratch)\n",
    "    full_optimizer = tf.train.GradientDescentOptimizer(learning_rate2)\n",
    "    full_train_op = full_optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Define the accuracy calculation of the trained model\n",
    "    prediction = tf.to_int32(tf.argmax(logits, 1))\n",
    "    correct_prediction = tf.equal(prediction, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorboard logging\n",
    "\n",
    " # Create a summary to monitor loss tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a log file to store all the data and summaries\n",
    "summary_writer  = tf.summary.FileWriter(log_path, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../pretrained/vgg/vgg_16.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Initialize all variables\n",
    "init_vgg(sess)  # load the pretrained weights\n",
    "sess.run(fc8_init)  # Freshly initialize last new layer of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Runs the model on the entire dataset and returns the accuracy of the predictions.\n",
    "'''\n",
    "def check_accuracy(sess, correct_prediction, is_training, dataset_init_op):\n",
    "    # Method to get the training or validation (is_training=False), accuracy\n",
    "    sess.run(dataset_init_op)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    while True:\n",
    "        try:\n",
    "            correct_pred = sess.run(correct_prediction, {is_training: False})   #get the predicitons\n",
    "            num_correct += correct_pred.sum()\n",
    "            num_samples += correct_pred.shape[0]\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 15\n",
      "Train accuracy: 0.940231\n",
      "Val accuracy: 0.918072\n",
      "Time for this epoch: 77 seconds\n",
      "\n",
      "Starting epoch 2 / 15\n",
      "Train accuracy: 0.951756\n",
      "Val accuracy: 0.946988\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 3 / 15\n",
      "Train accuracy: 0.966497\n",
      "Val accuracy: 0.954217\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 4 / 15\n",
      "Train accuracy: 0.966229\n",
      "Val accuracy: 0.966265\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 5 / 15\n",
      "Train accuracy: 0.972930\n",
      "Val accuracy: 0.966265\n",
      "Time for this epoch: 77 seconds\n",
      "\n",
      "Starting epoch 6 / 15\n",
      "Train accuracy: 0.976146\n",
      "Val accuracy: 0.966265\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 7 / 15\n",
      "Train accuracy: 0.980702\n",
      "Val accuracy: 0.966265\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 8 / 15\n",
      "Train accuracy: 0.981238\n",
      "Val accuracy: 0.973494\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 9 / 15\n",
      "Train accuracy: 0.974002\n",
      "Val accuracy: 0.975904\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 10 / 15\n",
      "Train accuracy: 0.983919\n",
      "Val accuracy: 0.975904\n",
      "Time for this epoch: 77 seconds\n",
      "\n",
      "Starting epoch 11 / 15\n",
      "Train accuracy: 0.985259\n",
      "Val accuracy: 0.975904\n",
      "Time for this epoch: 77 seconds\n",
      "\n",
      "Starting epoch 12 / 15\n",
      "Train accuracy: 0.986331\n",
      "Val accuracy: 0.978313\n",
      "Time for this epoch: 76 seconds\n",
      "\n",
      "Starting epoch 13 / 15\n",
      "Train accuracy: 0.987135\n",
      "Val accuracy: 0.978313\n",
      "Time for this epoch: 77 seconds\n",
      "\n",
      "Starting epoch 14 / 15\n",
      "Train accuracy: 0.987671\n",
      "Val accuracy: 0.985542\n",
      "Time for this epoch: 77 seconds\n",
      "\n",
      "Starting epoch 15 / 15\n",
      "Train accuracy: 0.988207\n",
      "Val accuracy: 0.983133\n",
      "Time for this epoch: 76 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs1):\n",
    "    # Run an epoch over the training data.\n",
    "    print('Starting epoch %d / %d' % (epoch + 1, num_epochs1))\n",
    "    start = time.perf_counter()\n",
    "    sess.run(train_init_op)\n",
    "    while True:\n",
    "        try:\n",
    "            _, summary  = sess.run([fc8_train_op, merged_summary_op], {is_training: True})\n",
    "            summary_writer.add_summary(summary, epoch)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # Check accuracy on the train and val sets every epoch.\n",
    "    train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "    val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "    print('Train accuracy: %f' % train_acc)\n",
    "    print('Val accuracy: %f' % val_acc)\n",
    "    print('Time for this epoch: %.0f seconds\\n' % (time.perf_counter() - start))\n",
    "\n",
    "    # Here you can add some code to do early stopping: validation accuracy is decreasing, while the trainings accuracy is increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 15\n",
      "Train accuracy: 0.989547\n",
      "Val accuracy: 0.978313\n",
      "Time for this epoch: 169 seconds\n",
      "\n",
      "Starting epoch 2 / 15\n",
      "Train accuracy: 0.989547\n",
      "Val accuracy: 0.985542\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 3 / 15\n",
      "Train accuracy: 0.989547\n",
      "Val accuracy: 0.985542\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 4 / 15\n",
      "Train accuracy: 0.992227\n",
      "Val accuracy: 0.985542\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 5 / 15\n",
      "Train accuracy: 0.991423\n",
      "Val accuracy: 0.987952\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 6 / 15\n",
      "Train accuracy: 0.991691\n",
      "Val accuracy: 0.987952\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 7 / 15\n",
      "Train accuracy: 0.990351\n",
      "Val accuracy: 0.987952\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 8 / 15\n",
      "Train accuracy: 0.990887\n",
      "Val accuracy: 0.990361\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 9 / 15\n",
      "Train accuracy: 0.990619\n",
      "Val accuracy: 0.990361\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 10 / 15\n",
      "Train accuracy: 0.991423\n",
      "Val accuracy: 0.990361\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 11 / 15\n",
      "Train accuracy: 0.993299\n",
      "Val accuracy: 0.990361\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 12 / 15\n",
      "Train accuracy: 0.993031\n",
      "Val accuracy: 0.990361\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 13 / 15\n",
      "Train accuracy: 0.994103\n",
      "Val accuracy: 0.992771\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 14 / 15\n",
      "Train accuracy: 0.992495\n",
      "Val accuracy: 0.992771\n",
      "Time for this epoch: 168 seconds\n",
      "\n",
      "Starting epoch 15 / 15\n",
      "Train accuracy: 0.994103\n",
      "Val accuracy: 0.987952\n",
      "Time for this epoch: 168 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the entire model for a few more epochs, continuing with the *same* weights.\n",
    "for epoch in range(num_epochs2):\n",
    "    print('Starting epoch %d / %d' % (epoch + 1, num_epochs2))\n",
    "    start = time.perf_counter()\n",
    "    sess.run(train_init_op)\n",
    "    while True:\n",
    "        try:\n",
    "            _, summary = sess.run([full_train_op,merged_summary_op], {is_training: True})\n",
    "            summary_writer.add_summary(summary, epoch + num_epochs1)\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # Check accuracy on the train and val sets every epoch\n",
    "    train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "    val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "    print('Train accuracy: %f' % train_acc)\n",
    "    print('Val accuracy: %f' % val_acc)\n",
    "    print('Time for this epoch: %.0f seconds\\n' % (time.perf_counter() - start))\n",
    "\n",
    "    # Here you can add some code to do early stopping: validation accuracy is decreasing, while the trainings accuracy is increasing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../pretrained/vgg-finetuned/vgg-finetuned-15-15'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally it is important to save the trained model\n",
    "# Create a saver object which will save the weights and variables of the trained model\n",
    "saver = tf.train.Saver()\n",
    "model_name = 'vgg-finetuned-%s-%s' % (num_epochs1, num_epochs2)\n",
    "saver.save(sess, os.path.join(save_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
